{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93588ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выбрано устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Выбрано устройство: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139d724",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d439f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "import mimetypes\n",
    "from project_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2201f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = Path().resolve()\n",
    "project_root = notebook_dir.parent\n",
    "input_video_path = project_root / \"data\" / \"crowd.mp4\"\n",
    "output_video_path_dir = project_root / \"results\"\n",
    "output_video_path_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e814dc",
   "metadata": {},
   "source": [
    "# Yolo_pretrained_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77aff6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_yolo_inference_on_video(\n",
    "    model_name: str,\n",
    "    input_video_path: Path,\n",
    "    output_dir: Path\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Запускает инференс YOLOv8 на видео и сохраняет результат.\n",
    "    \n",
    "    Аргументы:\n",
    "        model_name (str): Название предобученной модели YOLOv8 (например, 'yolov8n', 'yolov8s').\n",
    "        input_video_path (Path): Путь к входному видеофайлу.\n",
    "        output_dir (Path): Директория для сохранения результата.\n",
    "    \n",
    "    Возвращает:\n",
    "        Path: Путь к сохранённому видеофайлу.\n",
    "    \"\"\"\n",
    "    # Валидация и открытие видео\n",
    "    validate_video_file(input_video_path)\n",
    "    cap, meta = open_video_capture(input_video_path)\n",
    "\n",
    "    # Загрузка модели\n",
    "    model = YOLO(f\"{model_name}.pt\")\n",
    "\n",
    "    # Путь к выходному файлу\n",
    "    output_video_path = output_dir / f\"{model_name}_output.mp4\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Инициализация записи\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(output_video_path), fourcc, meta[\"fps\"], (meta[\"width\"], meta[\"height\"]))\n",
    "\n",
    "    print(f\"Обработка видео: {meta['total_frames']} кадров, {meta['fps']} FPS (модель: {model_name})\")\n",
    "\n",
    "    # Обработка кадров\n",
    "    for _ in tqdm(range(meta[\"total_frames\"]), desc=f\"{model_name} inference\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Инференс\n",
    "        results = model(frame, verbose=False)\n",
    "        boxes, confidences, class_ids = [], [], []\n",
    "\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                boxes.append(box.xyxy[0].cpu().numpy())\n",
    "                confidences.append(float(box.conf.item()))\n",
    "                class_ids.append(int(box.cls.item()))\n",
    "\n",
    "        # Отрисовка\n",
    "        frame = draw_detections(frame, boxes, confidences, class_ids)\n",
    "\n",
    "        # Запись\n",
    "        out.write(frame)\n",
    "\n",
    "    # Очистка ресурсов\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Результат сохранён: {output_video_path.resolve()}\")\n",
    "    return output_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f481b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Запуск инференса для модели: yolov8n\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolov8n)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov8n inference: 100%|██████████| 705/705 [00:26<00:00, 26.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov8n_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolov8s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ━━━━━━━━━━━━ 21.5MB 9.9MB/s 2.2s 2.1s<0.1ss31\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolov8s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov8s inference: 100%|██████████| 705/705 [00:48<00:00, 14.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov8s_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolov8m\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt': 100% ━━━━━━━━━━━━ 49.7MB 10.6MB/s 4.7s4.6s<0.0s7s8\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolov8m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov8m inference: 100%|██████████| 705/705 [01:34<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov8m_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolov8l\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'yolov8l.pt': 100% ━━━━━━━━━━━━ 83.7MB 10.8MB/s 7.7s.6s<0.4ss8s\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolov8l)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov8l inference: 100%|██████████| 705/705 [03:03<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov8l_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolov8x\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x.pt to 'yolov8x.pt': 100% ━━━━━━━━━━━━ 130.5MB 11.0MB/s 11.9s11.8s<0.1s3\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolov8x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov8x inference: 100%|██████████| 705/705 [04:18<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov8x_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolov9c\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov9c.pt to 'yolov9c.pt': 100% ━━━━━━━━━━━━ 49.4MB 10.3MB/s 4.8s4.8s<0.0s1s2\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolov9c)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov9c inference: 100%|██████████| 705/705 [02:19<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov9c_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolov9e\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov9e.pt to 'yolov9e.pt': 100% ━━━━━━━━━━━━ 112.1MB 10.7MB/s 10.5s 10.5s<0.0s\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolov9e)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov9e inference: 100%|██████████| 705/705 [04:21<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov9e_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolov10n\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10n.pt to 'yolov10n.pt': 100% ━━━━━━━━━━━━ 5.6MB 6.7MB/s 0.8s0.8s<0.0s4s5s\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolov10n)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov10n inference: 100%|██████████| 705/705 [00:27<00:00, 25.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov10n_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolov10s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10s.pt to 'yolov10s.pt': 100% ━━━━━━━━━━━━ 15.9MB 9.3MB/s 1.7s 1.6s<0.1s7s\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolov10s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov10s inference: 100%|██████████| 705/705 [00:45<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov10s_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolov10m\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10m.pt to 'yolov10m.pt': 100% ━━━━━━━━━━━━ 32.1MB 8.7MB/s 3.7s 3.7s<0.0ss6\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolov10m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov10m inference: 100%|██████████| 705/705 [01:25<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov10m_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolov10b\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10b.pt to 'yolov10b.pt': 100% ━━━━━━━━━━━━ 39.7MB 10.4MB/s 3.8s3.8s<0.0s1s3\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolov10b)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov10b inference: 100%|██████████| 705/705 [01:55<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov10b_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolov10l\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10l.pt to 'yolov10l.pt': 100% ━━━━━━━━━━━━ 50.0MB 10.7MB/s 4.7s4.6s<0.1s2s8\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolov10l)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov10l inference: 100%|██████████| 705/705 [02:23<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov10l_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolov10xyolo11n\n",
      "[!] Ошибка при запуске yolov10xyolo11n: [Errno 2] No such file or directory: 'yolov10xyolo11n.pt'\n",
      "\n",
      "[+] Запуск инференса для модели: yolo11s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt to 'yolo11s.pt': 100% ━━━━━━━━━━━━ 18.4MB 9.7MB/s 1.9s 1.9s<0.0ss17\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolo11s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolo11s inference: 100%|██████████| 705/705 [00:46<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolo11s_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolo11m\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt to 'yolo11m.pt': 100% ━━━━━━━━━━━━ 38.8MB 10.4MB/s 3.7s3.7s<0.1s2s2\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolo11m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolo11m inference: 100%|██████████| 705/705 [01:38<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolo11m_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolo11l\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt to 'yolo11l.pt': 100% ━━━━━━━━━━━━ 49.0MB 10.6MB/s 4.6s4.6s<0.0s4s3\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolo11l)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolo11l inference: 100%|██████████| 705/705 [02:00<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolo11l_output.mp4\n",
      "\n",
      "[+] Запуск инференса для модели: yolo11x\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x.pt to 'yolo11x.pt': 100% ━━━━━━━━━━━━ 109.3MB 10.9MB/s 10.0s9.9s<0.1ss3\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: yolo11x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolo11x inference: 100%|██████████| 705/705 [03:48<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolo11x_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "YOLO_MODELS = [\n",
    "    # YOLOv8\n",
    "    \"yolov8n\", \"yolov8s\", \"yolov8m\", \"yolov8l\", \"yolov8x\",\n",
    "    # YOLOv9\n",
    "    \"yolov9c\", \"yolov9e\",\n",
    "    # YOLOv10\n",
    "    \"yolov10n\", \"yolov10s\", \"yolov10m\", \"yolov10b\", \"yolov10l\", \"yolov10x\"\n",
    "    # YOLO11\n",
    "    \"yolo11n\", \"yolo11s\", \"yolo11m\", \"yolo11l\", \"yolo11x\"\n",
    "]\n",
    "\n",
    "for model_name in YOLO_MODELS:\n",
    "    print(f\"\\n[+] Запуск инференса для модели: {model_name}\")\n",
    "    try:\n",
    "        run_yolo_inference_on_video(model_name, input_video_path, output_video_path_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Ошибка при запуске {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed7f085",
   "metadata": {},
   "source": [
    "# SAHI_and_Yolo_pretrained_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f8840af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi.models.ultralytics import UltralyticsDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "import torch  # для проверки CUDA\n",
    "\n",
    "\n",
    "def run_yolo_sahi_inference_on_video(\n",
    "    model_name: str,\n",
    "    input_video_path: Path,\n",
    "    output_dir: Path,\n",
    "    slice_height: int = 640,\n",
    "    slice_width: int = 640,\n",
    "    overlap_height_ratio: float = 0.2,\n",
    "    overlap_width_ratio: float = 0.2,\n",
    "    confidence_threshold: float = 0.3\n",
    ") -> Path:\n",
    "    validate_video_file(input_video_path)\n",
    "    cap, meta = open_video_capture(input_video_path)\n",
    "\n",
    "    # Автоматическое определение устройства\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Используемое устройство: {device}\")\n",
    "\n",
    "    detection_model = UltralyticsDetectionModel(\n",
    "        model_path=f\"{model_name}.pt\",\n",
    "        confidence_threshold=confidence_threshold,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    output_video_path = output_dir / f\"{model_name}_sahi_output.mp4\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(output_video_path), fourcc, meta[\"fps\"], (meta[\"width\"], meta[\"height\"]))\n",
    "\n",
    "    print(f\"SAHI + {model_name} обработка: {meta['total_frames']} кадров, {meta['fps']} FPS\")\n",
    "\n",
    "    for _ in tqdm(range(meta[\"total_frames\"]), desc=f\"{model_name}+SAHI\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        result = get_sliced_prediction(\n",
    "            image=frame,\n",
    "            detection_model=detection_model,\n",
    "            slice_height=slice_height,\n",
    "            slice_width=slice_width,\n",
    "            overlap_height_ratio=overlap_height_ratio,\n",
    "            overlap_width_ratio=overlap_width_ratio,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        boxes, confidences, class_ids = [], [], []\n",
    "        for obj in result.object_prediction_list:\n",
    "            if obj.category.id != 0:  # только люди (COCO class 0)\n",
    "                continue\n",
    "            bbox = obj.bbox.to_xyxy()\n",
    "            boxes.append(bbox)\n",
    "            confidences.append(obj.score.value)\n",
    "            class_ids.append(obj.category.id)\n",
    "\n",
    "        frame = draw_detections(frame, boxes, confidences, class_ids)\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Результат сохранён: {output_video_path.resolve()}\")\n",
    "    return output_video_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80db672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cuda\n",
      "SAHI + yolov8s обработка: 705 кадров, 29 FPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov8s+SAHI: 100%|██████████| 705/705 [02:53<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov8s_sahi_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('E:/people_real_time_detection_and_tracking/results/yolov8s_sahi_output.mp4')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_yolo_sahi_inference_on_video(\"yolov8s\", input_video_path, output_video_path_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef5dd515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cuda\n",
      "SAHI + yolov8x обработка: 705 кадров, 29 FPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolov8x+SAHI: 100%|██████████| 705/705 [04:15<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov8x_sahi_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('E:/people_real_time_detection_and_tracking/results/yolov8x_sahi_output.mp4')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_yolo_sahi_inference_on_video(\"yolov8x\", input_video_path, output_video_path_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f623b0",
   "metadata": {},
   "source": [
    "# RT-DETR_pretrained_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28f9115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rt_detr_inference_on_video(\n",
    "    model_name: str,\n",
    "    input_video_path: Path,\n",
    "    output_dir: Path\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Запускает инференс RT-DETR на видео и сохраняет результат.\n",
    "    \n",
    "    Аргументы:\n",
    "        model_name (str): Название модели, например 'rtdetr-l', 'rtdetr-x'.\n",
    "        input_video_path (Path): Путь к входному видеофайлу.\n",
    "        output_dir (Path): Директория для сохранения результата.\n",
    "    \n",
    "    Возвращает:\n",
    "        Path: Путь к сохранённому видеофайлу.\n",
    "    \"\"\"\n",
    "    validate_video_file(input_video_path)\n",
    "    cap, meta = open_video_capture(input_video_path)\n",
    "\n",
    "    # Загрузка RT-DETR модели через Ultralytics\n",
    "    model = YOLO(f\"{model_name}.pt\")\n",
    "\n",
    "    output_video_path = output_dir / f\"{model_name}_output.mp4\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(output_video_path), fourcc, meta[\"fps\"], (meta[\"width\"], meta[\"height\"]))\n",
    "\n",
    "    print(f\"Обработка видео: {meta['total_frames']} кадров, {meta['fps']} FPS (модель: {model_name})\")\n",
    "\n",
    "    for _ in tqdm(range(meta[\"total_frames\"]), desc=f\"{model_name} inference\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Инференс\n",
    "        results = model(frame, verbose=False)\n",
    "        boxes, confidences, class_ids = [], [], []\n",
    "\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                boxes.append(box.xyxy[0].cpu().numpy())\n",
    "                confidences.append(float(box.conf.item()))\n",
    "                class_ids.append(int(box.cls.item()))\n",
    "\n",
    "        # Отрисовка (та же функция, что и для YOLO)\n",
    "        frame = draw_detections(frame, boxes, confidences, class_ids)\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Результат сохранён: {output_video_path.resolve()}\")\n",
    "    return output_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "620edacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/rtdetr-l.pt to 'rtdetr-l.pt': 100% ━━━━━━━━━━━━ 63.4MB 10.1MB/s 6.3s6.2s<0.1s3s4\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: rtdetr-l)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtdetr-l inference: 100%|██████████| 705/705 [00:34<00:00, 20.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\rtdetr-l_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('E:/people_real_time_detection_and_tracking/results/rtdetr-l_output.mp4')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_rt_detr_inference_on_video(\"rtdetr-l\", input_video_path, output_video_path_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4529026d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/rtdetr-x.pt to 'rtdetr-x.pt': 100% ━━━━━━━━━━━━ 129.5MB 9.5MB/s 13.6ss 13.6s<0.0s\n",
      "Обработка видео: 705 кадров, 29 FPS (модель: rtdetr-x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtdetr-x inference: 100%|██████████| 705/705 [00:49<00:00, 14.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\rtdetr-x_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('E:/people_real_time_detection_and_tracking/results/rtdetr-x_output.mp4')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_rt_detr_inference_on_video(\"rtdetr-x\", input_video_path, output_video_path_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec6e2b2",
   "metadata": {},
   "source": [
    "# SAHI_and_RT-DETR_pretrained_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb3c8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi.models.ultralytics import UltralyticsDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def run_rt_detr_sahi_inference_on_video(\n",
    "    model_name: str,\n",
    "    input_video_path: Path,\n",
    "    output_dir: Path,\n",
    "    slice_height: int = 640,\n",
    "    slice_width: int = 640,\n",
    "    overlap_height_ratio: float = 0.2,\n",
    "    overlap_width_ratio: float = 0.2,\n",
    "    confidence_threshold: float = 0.3\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Запускает инференс RT-DETR + SAHI на видео и сохраняет результат.\n",
    "    \n",
    "    Поддерживает модели: 'rtdetr-l', 'rtdetr-x'.\n",
    "    \"\"\"\n",
    "    validate_video_file(input_video_path)\n",
    "    cap, meta = open_video_capture(input_video_path)\n",
    "\n",
    "    # Автоматический выбор устройства\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Используемое устройство: {device}\")\n",
    "\n",
    "    # SAHI-совместимая модель (работает с любыми Ultralytics-моделями, включая RT-DETR)\n",
    "    detection_model = UltralyticsDetectionModel(\n",
    "        model_path=f\"{model_name}.pt\",\n",
    "        confidence_threshold=confidence_threshold,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    output_video_path = output_dir / f\"{model_name}_sahi_output.mp4\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(output_video_path), fourcc, meta[\"fps\"], (meta[\"width\"], meta[\"height\"]))\n",
    "\n",
    "    print(f\"SAHI + {model_name} обработка: {meta['total_frames']} кадров, {meta['fps']} FPS\")\n",
    "\n",
    "    for _ in tqdm(range(meta[\"total_frames\"]), desc=f\"{model_name}+SAHI\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # SAHI inference\n",
    "        result = get_sliced_prediction(\n",
    "            image=frame,\n",
    "            detection_model=detection_model,\n",
    "            slice_height=slice_height,\n",
    "            slice_width=slice_width,\n",
    "            overlap_height_ratio=overlap_height_ratio,\n",
    "            overlap_width_ratio=overlap_width_ratio,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        boxes, confidences, class_ids = [], [], []\n",
    "        for obj in result.object_prediction_list:\n",
    "            if obj.category.id != 0:  # class 0 = person\n",
    "                continue\n",
    "            bbox = obj.bbox.to_xyxy()\n",
    "            boxes.append(bbox)\n",
    "            confidences.append(obj.score.value)\n",
    "            class_ids.append(obj.category.id)\n",
    "\n",
    "        frame = draw_detections(frame, boxes, confidences, class_ids)\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Результат сохранён: {output_video_path.resolve()}\")\n",
    "    return output_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bbadb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cuda\n",
      "SAHI + rtdetr-x обработка: 705 кадров, 29 FPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtdetr-x+SAHI: 100%|██████████| 705/705 [05:28<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\rtdetr-x_sahi_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('E:/people_real_time_detection_and_tracking/results/rtdetr-x_sahi_output.mp4')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_rt_detr_sahi_inference_on_video(\"rtdetr-x\", input_video_path, output_video_path_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3869e4e0",
   "metadata": {},
   "source": [
    "# SAHI_and_RT-DETR_pretrained_inference\n",
    "## BoT-SORT_post-processing_with_REID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22cd3bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "BOT_SORT_PATH = project_root / \"BoT-SORT\"\n",
    "\n",
    "if not (BOT_SORT_PATH / \"tracker\" / \"bot_sort.py\").exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Папка BoT-SORT не найдена по пути: {BOT_SORT_PATH.resolve()}\\n\"\n",
    "        \"Выполните в терминале (в папке проекта):\\n\"\n",
    "        \"git clone https://github.com/NirAharon/BoT-SORT.git\"\n",
    "    )\n",
    "\n",
    "# === КЛЮЧЕВОЕ ИЗМЕНЕНИЕ: добавляем КОРНЕВУЮ папку BoT-SORT в sys.path ===\n",
    "sys.path.insert(0, str(BOT_SORT_PATH))\n",
    "\n",
    "# Теперь этот импорт будет работать\n",
    "from tracker.bot_sort import BoTSORT\n",
    "\n",
    "from sahi.models.ultralytics import UltralyticsDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "\n",
    "\n",
    "def run_rt_detr_sahi_inference_on_video(\n",
    "    model_name: str,\n",
    "    input_video_path: Path,\n",
    "    output_dir: Path,\n",
    "    slice_height: int = 640,\n",
    "    slice_width: int = 640,\n",
    "    overlap_height_ratio: float = 0.2,\n",
    "    overlap_width_ratio: float = 0.2,\n",
    "    confidence_threshold: float = 0.3\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    SAHI + RT-DETR + BoT-SORT трекинг людей (class_id=0).\n",
    "    Использует оригинальный BoT-SORT с ReID.\n",
    "    \"\"\"\n",
    "    validate_video_file(input_video_path)\n",
    "    cap, meta = open_video_capture(input_video_path)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Устройство: {device}\")\n",
    "\n",
    "    detection_model = UltralyticsDetectionModel(\n",
    "        model_path=f\"{model_name}.pt\",\n",
    "        confidence_threshold=confidence_threshold,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    output_path = output_dir / f\"{model_name}_sahi_botsort_output.mp4\"\n",
    "    out = cv2.VideoWriter(str(output_path), cv2.VideoWriter_fourcc(*'mp4v'), meta[\"fps\"], (meta[\"width\"], meta[\"height\"]))\n",
    "\n",
    "    # === Инициализация BoT-SORT с ReID ===\n",
    "    from argparse import Namespace\n",
    "\n",
    "    reid_config = str(BOT_SORT_PATH / \"fast_reid\" / \"configs\" / \"MOT17\" / \"sbs_S50.yml\")\n",
    "    reid_weights = str(BOT_SORT_PATH / \"pretrained\" / \"sbs_S50_market1501.pth\")\n",
    "\n",
    "    tracker_args = Namespace(\n",
    "        track_high_thresh=0.5,\n",
    "        track_low_thresh=0.1,\n",
    "        new_track_thresh=0.4,\n",
    "        track_buffer=30,\n",
    "        match_thresh=0.8,\n",
    "        proximity_thresh=0.5,\n",
    "        appearance_thresh=0.2,\n",
    "        cmc_method='sparseOptFlow',\n",
    "        with_reid=True,\n",
    "        fast_reid_config=reid_config,\n",
    "        fast_reid_weights=reid_weights,\n",
    "        device='cuda',\n",
    "        name='BoT-SORT',      \n",
    "        ablation=False,\n",
    "        mot20=False        \n",
    "    )\n",
    "    tracker = BoTSORT(args=tracker_args, frame_rate=meta[\"fps\"])\n",
    "\n",
    "    print(f\"Обработка: SAHI + {model_name} + BoT-SORT (с ReID), {meta['total_frames']} кадров\")\n",
    "\n",
    "    for _ in tqdm(range(meta[\"total_frames\"]), desc=\"Трекинг\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # SAHI inference\n",
    "        result = get_sliced_prediction(\n",
    "            image=frame,\n",
    "            detection_model=detection_model,\n",
    "            slice_height=slice_height,\n",
    "            slice_width=slice_width,\n",
    "            overlap_height_ratio=overlap_height_ratio,\n",
    "            overlap_width_ratio=overlap_width_ratio,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Собираем только людей (class_id = 0)\n",
    "        dets = []\n",
    "        for obj in result.object_prediction_list:\n",
    "            if obj.category.id != 0:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = obj.bbox.to_xyxy()\n",
    "            conf = obj.score.value\n",
    "            dets.append([x1, y1, x2, y2, conf])\n",
    "        dets = np.array(dets) if dets else np.empty((0, 5))\n",
    "\n",
    "        # Обновление трекера\n",
    "        tracked_objects = tracker.update(dets, frame)\n",
    "\n",
    "        # Функция для получения цвета по ID\n",
    "        def get_color_from_id(track_id):\n",
    "            np.random.seed(track_id)\n",
    "            return np.random.randint(0, 255, size=3).tolist()\n",
    "\n",
    "        # Отрисовка\n",
    "        for track in tracked_objects:\n",
    "            x1, y1, x2, y2 = map(int, track.tlbr)\n",
    "            track_id = int(track.track_id)\n",
    "            color = get_color_from_id(track_id)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f'ID: {track_id}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Результат сохранён: {output_path.resolve()}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21bdb053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Устройство: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'backbone.layer1.0.downsample.1.weight' to the model due to incompatible shapes: (256,) in the checkpoint but (256, 64, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'backbone.layer2.0.downsample.1.weight' to the model due to incompatible shapes: (512,) in the checkpoint but (512, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'backbone.layer3.0.downsample.1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (1024, 512, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'backbone.layer4.0.downsample.1.weight' to the model due to incompatible shapes: (2048,) in the checkpoint but (2048, 1024, 1, 1) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка: SAHI + rtdetr-x + BoT-SORT (с ReID), 705 кадров\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Трекинг: 100%|██████████| 705/705 [05:15<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\rtdetr-x_sahi_botsort_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('E:/people_real_time_detection_and_tracking/results/rtdetr-x_sahi_botsort_output.mp4')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_rt_detr_sahi_inference_on_video(\"rtdetr-x\", input_video_path, output_video_path_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c07be",
   "metadata": {},
   "source": [
    "# SAHI_and_Yolov8_pretrained_inference\n",
    "## BoT-SORT_post-processing_with_REID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bdb302c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Устройство: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'backbone.layer1.0.downsample.1.weight' to the model due to incompatible shapes: (256,) in the checkpoint but (256, 64, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'backbone.layer2.0.downsample.1.weight' to the model due to incompatible shapes: (512,) in the checkpoint but (512, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'backbone.layer3.0.downsample.1.weight' to the model due to incompatible shapes: (1024,) in the checkpoint but (1024, 512, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'backbone.layer4.0.downsample.1.weight' to the model due to incompatible shapes: (2048,) in the checkpoint but (2048, 1024, 1, 1) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка: SAHI + yolov8x + BoT-SORT (с ReID), 705 кадров\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Трекинг: 100%|██████████| 705/705 [04:46<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат сохранён: E:\\people_real_time_detection_and_tracking\\results\\yolov8x_sahi_botsort_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('E:/people_real_time_detection_and_tracking/results/yolov8x_sahi_botsort_output.mp4')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_rt_detr_sahi_inference_on_video(\"yolov8x\", input_video_path, output_video_path_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "antideepfake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
